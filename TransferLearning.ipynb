{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMamgzwHL1fSGn0PXQ7QSEt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andremcq/MLIndividualAssessment/blob/main/TransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0yct0IgP9XsW",
        "outputId": "cb820e36-1f83-44fd-ac13-61e306aed92e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF5irsuYDbVI",
        "outputId": "675c1570-8b96-4ff3-ff78-d74ce6ffc411"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.7.0\n",
            "Hub version: 0.12.0\n",
            "GPU is available\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"archive.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"data\")\n"
      ],
      "metadata": {
        "id": "o7xUWrrP-BA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(\"Test.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"data\")"
      ],
      "metadata": {
        "id": "UkecKEyuikMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "#import matplotlib.pyplot as plt\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "BTG6vb3PinYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "n_classes = 43"
      ],
      "metadata": {
        "id": "vIBI1q9oiuy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n",
        "\n",
        "train_dataset = image_generator.flow_from_directory(batch_size=32,\n",
        "                                                 directory='data/Train',\n",
        "                                                 shuffle=True,\n",
        "                                                 target_size=IMAGE_SHAPE, \n",
        "                                                 subset=\"training\",\n",
        "                                                 class_mode='categorical')\n",
        "\n",
        "validation_dataset = image_generator.flow_from_directory(batch_size=32,\n",
        "                                                 directory='data/Train',\n",
        "                                                 shuffle=True,\n",
        "                                                 target_size=IMAGE_SHAPE, \n",
        "                                                 subset=\"validation\",\n",
        "                                                 class_mode='categorical')\n",
        "\n",
        "test_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_image_test_data = image_generator.flow_from_directory(batch_size=32,\n",
        "                                                 directory='data/Test',\n",
        "                                                 shuffle=True,\n",
        "                                                 target_size=IMAGE_SHAPE, \n",
        "                                                 subset=\"training\",\n",
        "                                                 class_mode='categorical')\n"
      ],
      "metadata": {
        "id": "vpwQnWtIiyHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "                class_weight = 'balanced',\n",
        "                classes = np.unique(train_dataset.classes), \n",
        "                y = train_dataset.classes)\n",
        "class_weights = {i : class_weights[i] for i in range(n_classes)}\n",
        "class_weights"
      ],
      "metadata": {
        "id": "GcXdK9Whi4DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n",
        "    \"\"\"\n",
        "    Compiles a model integrated with VGG16 pretrained layers\n",
        "    \n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training. Defaults to 'RMSProp'\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze.\n",
        "                If set to 0, all pretrained layers will freeze during training\n",
        "    \"\"\"\n",
        "    \n",
        "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
        "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
        "    conv_base = VGG16(include_top=True,\n",
        "                     weights='imagenet', \n",
        "                     input_shape=input_shape)\n",
        "    \n",
        "    # Drop FC-1000\n",
        "    conv_base = Model(inputs=conv_base.inputs, outputs=conv_base.layers[-2].output)\n",
        "    \n",
        "    #print(conv_base.summary())\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
        "    # depending on the size of the fine-tuning parameter.\n",
        "    if fine_tune > 0:\n",
        "        for layer in conv_base.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in conv_base.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
        "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
        "    top_model = conv_base.output\n",
        "\n",
        "    #top_model = Dropout(0.2)(top_model)\n",
        "    \n",
        "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
        "      \n",
        "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
        "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "NsCSyV3ri5Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224, 224, 3)\n",
        "\n",
        "vgg_model_ft = create_model(input_shape, n_classes)\n",
        "vgg_model_ft.summary()"
      ],
      "metadata": {
        "id": "biwkTeJPjBdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "batch_size = 32\n",
        "history = vgg_model_ft.fit(\n",
        "    train_dataset,\n",
        "    batch_size = batch_size,\n",
        "    steps_per_epoch = train_dataset.samples // batch_size,\n",
        "    validation_data = validation_dataset, \n",
        "    validation_steps = validation_dataset.samples // batch_size,\n",
        "    verbose = 1,\n",
        "    epochs = 30, \n",
        "    class_weight = class_weights,\n",
        "          callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "1QhzkzPkjFNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "batch_size = 32\n",
        "history = vgg_model_ft.fit(\n",
        "    train_dataset,\n",
        "    batch_size = batch_size,\n",
        "    steps_per_epoch = train_dataset.samples // batch_size,\n",
        "    validation_data = validation_dataset, \n",
        "    validation_steps = validation_dataset.samples // batch_size,\n",
        "    verbose = 1,\n",
        "    epochs = 30, \n",
        "    #class_weight = class_weights,\n",
        "          callbacks=[tensorboard_callback])\n",
        "history"
      ],
      "metadata": {
        "id": "D2K0R1GIjIk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model_ft.evaluate(test_image_test_data,callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "joyn-E5FjQLa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}